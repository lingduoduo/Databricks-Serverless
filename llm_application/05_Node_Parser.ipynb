{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8901e340-f23c-4263-8dcc-8e887f407be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (0.3.27)\nCollecting langchain\n  Using cached langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: langchain-community in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (0.3.31)\nCollecting langchain-community\n  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: langchain-databricks in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (0.1.2)\nRequirement already satisfied: faiss-cpu in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (1.13.2)\nRequirement already satisfied: tiktoken in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (0.12.0)\nRequirement already satisfied: langchain_text_splitters in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (0.3.11)\nCollecting langchain_text_splitters\n  Using cached langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting langchain_experimental\n  Downloading langchain_experimental-0.4.1-py3-none-any.whl.metadata (1.3 kB)\nCollecting langchain-core<2.0.0,>=1.2.1 (from langchain)\n  Using cached langchain_core-1.2.5-py3-none-any.whl.metadata (3.7 kB)\nCollecting langgraph<1.1.0,>=1.0.2 (from langchain)\n  Using cached langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /databricks/python3/lib/python3.12/site-packages (from langchain) (2.10.6)\nCollecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n  Using cached langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-community) (2.0.45)\nRequirement already satisfied: requests<3.0.0,>=2.32.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-community) (2.32.5)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-community) (3.13.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-community) (2.12.0)\nRequirement already satisfied: langsmith<1.0.0,>=0.1.125 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-community) (0.5.2)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: numpy>=1.26.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-community) (2.1.3)\nRequirement already satisfied: databricks-vectorsearch<0.41,>=0.40 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-databricks) (0.40)\nINFO: pip is looking at multiple versions of langchain-databricks to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-databricks\n  Using cached langchain_databricks-0.1.2-py3-none-any.whl.metadata (3.3 kB)\n  Using cached langchain_databricks-0.1.1-py3-none-any.whl.metadata (5.9 kB)\n  Using cached langchain_databricks-0.1.0-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-community\n  Using cached langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\nINFO: pip is still looking at multiple versions of langchain-databricks to determine which version is compatible with other requirements. This could take a while.\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Using cached langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n  Using cached langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n  Using cached langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.28-py3-none-any.whl.metadata (2.9 kB)\nINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n  Using cached langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n  Using cached langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n  Using cached langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nINFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n  Using cached langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n  Using cached langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n  Using cached langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n  Using cached langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n  Using cached langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Using cached langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\nCollecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n  Using cached SQLAlchemy-2.0.35-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (9.6 kB)\nCollecting langchain-community\n  Using cached langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.6-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n  Using cached langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n  Using cached langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n  Using cached langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n  Using cached langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n  Using cached langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\nCollecting langchain\n  Using cached langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\nCollecting langchain-community\n  Using cached langchain_community-0.2.18-py3-none-any.whl.metadata (2.7 kB)\n  Using cached langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n  Using cached langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n  Using cached langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n  Using cached langchain_community-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n  Using cached langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n  Using cached langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n  Using cached langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n  Using cached langchain_community-0.2.9-py3-none-any.whl.metadata (2.5 kB)\n  Using cached langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n  Using cached langchain_community-0.2.6-py3-none-any.whl.metadata (2.5 kB)\n  Using cached langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\n  Using cached langchain_community-0.2.4-py3-none-any.whl.metadata (2.4 kB)\n  Using cached langchain_community-0.2.3-py3-none-any.whl.metadata (9.0 kB)\n  Using cached langchain_community-0.2.2-py3-none-any.whl.metadata (8.9 kB)\n  Using cached langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\n  Using cached langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n  Using cached langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n  Using cached langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n  Using cached langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n  Using cached langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n  Using cached langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n  Using cached langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n  Using cached langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n  Using cached langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n  Using cached langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n  Using cached langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n  Using cached langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n  Using cached langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n  Using cached langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n  Using cached langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n  Using cached langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n  Using cached langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n  Using cached langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n  Using cached langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n  Using cached langchain_community-0.0.19-py3-none-any.whl.metadata (7.9 kB)\n  Using cached langchain_community-0.0.18-py3-none-any.whl.metadata (7.9 kB)\n  Using cached langchain_community-0.0.17-py3-none-any.whl.metadata (7.9 kB)\n  Using cached langchain_community-0.0.16-py3-none-any.whl.metadata (7.8 kB)\n  Using cached langchain_community-0.0.15-py3-none-any.whl.metadata (7.6 kB)\n  Using cached langchain_community-0.0.14-py3-none-any.whl.metadata (7.5 kB)\n  Using cached langchain_community-0.0.13-py3-none-any.whl.metadata (7.5 kB)\n  Using cached langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n  Using cached langchain_community-0.0.11-py3-none-any.whl.metadata (7.3 kB)\n  Using cached langchain_community-0.0.10-py3-none-any.whl.metadata (7.3 kB)\n  Using cached langchain_community-0.0.8-py3-none-any.whl.metadata (7.3 kB)\n  Using cached langchain_community-0.0.7-py3-none-any.whl.metadata (7.3 kB)\n  Using cached langchain_community-0.0.6-py3-none-any.whl.metadata (7.2 kB)\n  Using cached langchain_community-0.0.5-py3-none-any.whl.metadata (7.1 kB)\n  Using cached langchain_community-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n  Using cached langchain_community-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n  Using cached langchain_community-0.0.2-py3-none-any.whl.metadata (5.8 kB)\n  Using cached langchain_community-0.0.1-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain\n  Using cached langchain-1.1.3-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (24.1)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.12.2)\nRequirement already satisfied: uuid-utils<1.0,>=0.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n  Using cached langchain-1.1.2-py3-none-any.whl.metadata (4.9 kB)\n  Using cached langchain-1.1.1-py3-none-any.whl.metadata (4.9 kB)\n  Using cached langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\n  Using cached langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n  Using cached langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n  Using cached langchain-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n  Using cached langchain-1.0.5-py3-none-any.whl.metadata (4.9 kB)\n  Using cached langchain-1.0.4-py3-none-any.whl.metadata (4.9 kB)\n  Using cached langchain-1.0.3-py3-none-any.whl.metadata (4.7 kB)\n  Using cached langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n  Using cached langchain-1.0.1-py3-none-any.whl.metadata (4.7 kB)\n  Using cached langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain) (0.3.81)\nRequirement already satisfied: mlflow>=2.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langchain-databricks) (2.22.4)\nRequirement already satisfied: scipy>=1.11 in /databricks/python3/lib/python3.12/site-packages (from langchain-databricks) (1.15.1)\nRequirement already satisfied: regex>=2022.1.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from tiktoken) (2025.11.3)\nINFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain_experimental\n  Downloading langchain_experimental-0.4.0-py3-none-any.whl.metadata (1.3 kB)\n  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: mlflow-skinny<3,>=2.11.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (2.22.4)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (4.25.8)\nRequirement already satisfied: deprecation>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (2.1.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.27.0)\nRequirement already satisfied: orjson>=3.9.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (3.1.2)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (3.1.5)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (1.17.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (7.1.0)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (23.0.0)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (3.10)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (3.10.0)\nRequirement already satisfied: pandas!=2.3.0,<3 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (2.2.3)\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=2.16.0->langchain-databricks) (1.6.1)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (5.5.1)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (0.49.0)\nRequirement already satisfied: fastapi<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (0.115.12)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (6.6.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (1.32.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (1.32.1)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (0.5.3)\nRequirement already satisfied: uvicorn<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (0.34.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\nRequirement already satisfied: python-dotenv>=0.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.1.31)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow>=2.16.0->langchain-databricks) (1.3.10)\nRequirement already satisfied: blinker>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from Flask<4->mlflow>=2.16.0->langchain-databricks) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from Flask<4->mlflow>=2.16.0->langchain-databricks) (2.2.0)\nRequirement already satisfied: markupsafe>=2.1.1 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow>=2.16.0->langchain-databricks) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from Flask<4->mlflow>=2.16.0->langchain-databricks) (3.1.4)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from graphene<4->mlflow>=2.16.0->langchain-databricks) (3.2.7)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ee48a9c2-59f8-4ec7-83bd-e3d32e7bfa16/lib/python3.12/site-packages (from graphene<4->mlflow>=2.16.0->langchain-databricks) (3.2.0)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow>=2.16.0->langchain-databricks) (2.9.0.post0)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.6.2)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.2)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=2.16.0->langchain-databricks) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=2.16.0->langchain-databricks) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=2.16.0->langchain-databricks) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=2.16.0->langchain-databricks) (1.4.8)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=2.16.0->langchain-databricks) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=2.16.0->langchain-databricks) (3.2.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas!=2.3.0,<3->mlflow>=2.16.0->langchain-databricks) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas!=2.3.0,<3->mlflow>=2.16.0->langchain-databricks) (2024.1)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn<2->mlflow>=2.16.0->langchain-databricks) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn<2->mlflow>=2.16.0->langchain-databricks) (3.5.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (2.40.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /databricks/python3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (3.21.0)\nRequirement already satisfied: deprecated>=1.2.6 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (1.2.13)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (0.53b1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow>=2.16.0->langchain-databricks) (1.16.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (1.17.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (5.0.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (4.9.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks) (0.4.8)\nDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\nInstalling collected packages: langchain_experimental\nSuccessfully installed langchain_experimental-0.3.4\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain langchain-community langchain-databricks faiss-cpu tiktoken langchain_text_splitters langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75b641c7-0eb8-4e2f-8d17-20c47d967d84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acef54e8-4f3d-42ab-b96f-b60ca42326f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Callable\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_databricks import ChatDatabricks, DatabricksEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcda38ce-d178-418a-9f3e-66c0df7ecdcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95b1f725-60ba-4c28-b19e-21107de2b062",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Callable\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_databricks import ChatDatabricks, DatabricksEmbeddings\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1) Databricks LLM + Embeddings\n",
    "# -----------------------\n",
    "# Make sure your Databricks auth is configured (e.g., DATABRICKS_HOST + DATABRICKS_TOKEN)\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-1-8b-instruct\"\n",
    "EMBEDDING_ENDPOINT_NAME = \"databricks-bge-large-en\"  # <-- change to your embedding endpoint name\n",
    "\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.1)\n",
    "embeddings = DatabricksEmbeddings(endpoint=EMBEDDING_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69b03608-cbeb-476e-8ee0-28e4db57563d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Why does chunking cause context fragmentation?'\npage_content='1. Loss of Coherence'\npage_content='When a complete semantic unit is forcibly split,'\npage_content='lit, the information becomes incomplete'\npage_content='(the meaning is broken)'\npage_content='. For example, if an argument is distributed acros'\npage_content='across two chunks,'\npage_content='neither chunk alone can accurately convey the ori'\npage_content='e original meaning'\npage_content='. This interferes with'\npage_content='the language model’s understanding and generation'\npage_content='ation, leading to incomplete or even'\npage_content='misleading outputs.\n\n2. Diluted Relevance'\npage_content='If a chunk mixes relevant and irrelevant content,'\npage_content='tent, the key information becomes diluted'\npage_content='.'\npage_content='This negatively affects the accuracy of vector re'\npage_content='or representations and, in turn, lowers'\npage_content='retrieval ranking performance.'\npage_content='3. Scattered Information'\npage_content='For complex questions that require multi-hop reas'\npage_content='reasoning, relevant information may be'\npage_content='scattered across multiple chunks'\npage_content='. If not all of them are retrieved, a RAG system c'\npage_content='tem cannot'\npage_content='produce a complete answer.'\npage_content='When these issues compound, they directly lead to'\npage_content='ad to a “garbage in, garbage out” effect,'\npage_content='and may even increase the risk of model hallucina'\npage_content='ucinations'\npage_content='.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=5,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\", \".\", \"\"],\n",
    ")\n",
    "\n",
    "text = \"\"\"\n",
    "Why does chunking cause context fragmentation?\n",
    "\n",
    "1. Loss of Coherence\n",
    "When a complete semantic unit is forcibly split, the information becomes incomplete\n",
    "(the meaning is broken). For example, if an argument is distributed across two chunks,\n",
    "neither chunk alone can accurately convey the original meaning. This interferes with\n",
    "the language model’s understanding and generation, leading to incomplete or even\n",
    "misleading outputs.\n",
    "\n",
    "2. Diluted Relevance\n",
    "If a chunk mixes relevant and irrelevant content, the key information becomes diluted.\n",
    "This negatively affects the accuracy of vector representations and, in turn, lowers\n",
    "retrieval ranking performance.\n",
    "\n",
    "3. Scattered Information\n",
    "For complex questions that require multi-hop reasoning, relevant information may be\n",
    "scattered across multiple chunks. If not all of them are retrieved, a RAG system cannot\n",
    "produce a complete answer.\n",
    "\n",
    "When these issues compound, they directly lead to a “garbage in, garbage out” effect,\n",
    "and may even increase the risk of model hallucinations.\n",
    "\"\"\"\n",
    "\n",
    "# Text to be processed\n",
    "documents = text_splitter.create_documents([text])\n",
    "\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75d48160-7008-4c0b-81e6-1c26924fe02b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00a46cdd-8ca8-421c-acc2-b26138b51c57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic splitting produced 2 chunks:\n--- Chunk 1 ---\nArtificial intelligence (AI) is fundamentally transforming the healthcare industry. AI algorithms can analyze medical images and diagnose diseases such as cancer earlier and more accurately than human radiologists. In addition, AI plays a critical role in drug discovery by predicting the effectiveness of chemical compounds, significantly reducing the time required to bring new drugs to market. Shifting gears, let us talk about financial technology (FinTech).\n--------------------\n--- Chunk 2 ---\nMobile payments have become mainstream worldwide, with digital wallets and contactless payments reshaping consumer behavior. Blockchain technology provides decentralized solutions for cross-border payments and asset tokenization, with the potential to reshape the underlying infrastructure of the entire financial system.\n--------------------\n"
     ]
    }
   ],
   "source": [
    "# LangChain equivalent of LlamaIndex SemanticSplitterNodeParser\n",
    "# pip install -U langchain-text-splitters langchain-openai\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Example text containing multiple topics\n",
    "multi_theme_text = (\n",
    "    \"Artificial intelligence (AI) is fundamentally transforming the healthcare industry. \"\n",
    "    \"AI algorithms can analyze medical images and diagnose diseases such as cancer earlier \"\n",
    "    \"and more accurately than human radiologists. \"\n",
    "    \"In addition, AI plays a critical role in drug discovery by predicting the effectiveness \"\n",
    "    \"of chemical compounds, significantly reducing the time required to bring new drugs to market. \"\n",
    "    \"Shifting gears, let us talk about financial technology (FinTech). \"\n",
    "    \"Mobile payments have become mainstream worldwide, with digital wallets and contactless \"\n",
    "    \"payments reshaping consumer behavior. \"\n",
    "    \"Blockchain technology provides decentralized solutions for cross-border payments and \"\n",
    "    \"asset tokenization, with the potential to reshape the underlying infrastructure of the \"\n",
    "    \"entire financial system.\"\n",
    ")\n",
    "\n",
    "# Create a LangChain Document\n",
    "docs = [Document(page_content=multi_theme_text)]\n",
    "\n",
    "# Initialize semantic chunker (closest LangChain equivalent)\n",
    "splitter = SemanticChunker(\n",
    "    embeddings=embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=90,  # roughly analogous to LlamaIndex's percentile threshold\n",
    ")\n",
    "\n",
    "# Perform semantic splitting\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# Print results\n",
    "print(f\"Semantic splitting produced {len(chunks)} chunks:\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(chunk.page_content)\n",
    "    print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83e6d25a-c31d-4321-87f4-2e758647c66b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DenseXRetrievalPack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5023ba3b-0b5b-4e9e-a4cc-223b418ec58c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nExtracted propositions:\n['The Eiffel Tower is located in Paris.', 'The Eiffel Tower was built in 1889.']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Prompt (force JSON-only)\n",
    "# -----------------------------\n",
    "PROPOSITIONS_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"You are a precise information extraction system.\n",
    "\n",
    "Task: Decompose the given Content into clear, simple propositions that are interpretable out of context.\n",
    "\n",
    "Rules:\n",
    "1) Split compound sentences into simple sentences. Keep original phrasing when possible.\n",
    "2) If a named entity has extra descriptive info, put that info into its own proposition.\n",
    "3) Decontextualize: replace pronouns with the full entity names they refer to.\n",
    "4) Output MUST be a JSON array of strings ONLY (no markdown, no extra text).\n",
    "\n",
    "Content:\n",
    "{node_text}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Robust parsing helpers\n",
    "# -----------------------------\n",
    "def _strip_code_fences(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    # Remove opening fence like ```json or ``` (any tag)\n",
    "    text = re.sub(r\"^\\s*```[a-zA-Z0-9_-]*\\s*\", \"\", text)\n",
    "    # Remove trailing fence\n",
    "    text = re.sub(r\"\\s*```\\s*$\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def _extract_first_json_array(text: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Extract the first JSON array from a possibly messy response like:\n",
    "      - Output: [...]\n",
    "      - ```json [...] ```\n",
    "      - Explanation ... [...] trailing text\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    text = _strip_code_fences(text)\n",
    "\n",
    "    start = text.find(\"[\")\n",
    "    end = text.rfind(\"]\")\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        return None\n",
    "\n",
    "    return text[start : end + 1].strip()\n",
    "\n",
    "\n",
    "def _message_to_text(msg: Any) -> str:\n",
    "    \"\"\"\n",
    "    Databricks/LangChain messages can sometimes be:\n",
    "      - content: str\n",
    "      - content: list[dict] (blocks)\n",
    "    Convert robustly to plain text.\n",
    "    \"\"\"\n",
    "    if msg is None:\n",
    "        return \"\"\n",
    "\n",
    "    content = getattr(msg, \"content\", \"\")\n",
    "\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "\n",
    "    if isinstance(content, list):\n",
    "        parts: List[str] = []\n",
    "        for block in content:\n",
    "            if isinstance(block, str):\n",
    "                parts.append(block)\n",
    "            elif isinstance(block, dict):\n",
    "                # common patterns\n",
    "                if isinstance(block.get(\"text\"), str):\n",
    "                    parts.append(block[\"text\"])\n",
    "                elif isinstance(block.get(\"content\"), str):\n",
    "                    parts.append(block[\"content\"])\n",
    "        return \"\\n\".join(parts).strip()\n",
    "\n",
    "    return str(content).strip()\n",
    "\n",
    "\n",
    "def safe_json_list(text: str, *, debug: bool = False) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse a list[str] from model output.\n",
    "    Returns [] only if it truly can't parse a JSON array.\n",
    "    \"\"\"\n",
    "    candidate = _extract_first_json_array(text)\n",
    "    if not candidate:\n",
    "        if debug:\n",
    "            print(\"[DEBUG] No JSON array found in output.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = json.loads(candidate)\n",
    "    except json.JSONDecodeError as e:\n",
    "        if debug:\n",
    "            print(\"[DEBUG] JSONDecodeError:\", e)\n",
    "            print(\"[DEBUG] Candidate snippet:\", candidate[:800])\n",
    "        return []\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "        if debug:\n",
    "            print(\"[DEBUG] Parsed JSON is not a list:\", type(data))\n",
    "        return []\n",
    "\n",
    "    return [x for x in data if isinstance(x, str)]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Core extraction function\n",
    "# -----------------------------\n",
    "def extract_propositions(node_text: str, llm: Any, *, debug: bool = True) -> List[str]:\n",
    "    prompt = PROPOSITIONS_PROMPT.format(node_text=node_text)\n",
    "\n",
    "    msg = llm.invoke(prompt)\n",
    "    raw_text = _message_to_text(msg).strip()\n",
    "\n",
    "    props = safe_json_list(raw_text, debug=debug)\n",
    "\n",
    "    if debug and not props:\n",
    "        print(\"\\n[DEBUG] Raw model output (first 1200 chars):\")\n",
    "        print(raw_text[:1200])\n",
    "        ak = getattr(msg, \"additional_kwargs\", None)\n",
    "        if isinstance(ak, dict) and ak:\n",
    "            print(\"\\n[DEBUG] additional_kwargs keys:\", list(ak.keys()))\n",
    "\n",
    "    return props\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Test\n",
    "# -----------------------------\n",
    "test_text = \"The Eiffel Tower is located in Paris and was built in 1889.\"\n",
    "\n",
    "propositions = extract_propositions(test_text, llm, debug=True)\n",
    "print(\"\\nExtracted propositions:\")\n",
    "print(propositions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ab9f3f0-f350-423a-a8a4-3d2989da7158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 in-memory documents.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1) In-memory sample documents (replace dir_path)\n",
    "# -----------------------------\n",
    "raw_docs = [\n",
    "    Document(\n",
    "        page_content=(\n",
    "            \"The Eiffel Tower is located in Paris, France. \"\n",
    "            \"It was constructed between 1887 and 1889 and officially opened in 1889 \"\n",
    "            \"for the World's Fair (Exposition Universelle). \"\n",
    "            \"The tower was designed by Gustave Eiffel's engineering company.\"\n",
    "        ),\n",
    "        metadata={\"source\": \"eiffel_tower\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=(\n",
    "            \"The Statue of Liberty is located in New York Harbor. \"\n",
    "            \"It was a gift from France to the United States and was dedicated in 1886. \"\n",
    "            \"The statue was designed by Frédéric Auguste Bartholdi.\"\n",
    "        ),\n",
    "        metadata={\"source\": \"statue_of_liberty\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(raw_docs)} in-memory documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3179526e-4a93-4bd0-b850-1a5403ebcbb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 11 proposition documents.\n\n=== Answer ===\nBetween 1887 and 1889.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Build proposition documents (DenseX-style indexing step)\n",
    "# -----------------------------\n",
    "prop_docs: List[Document] = []\n",
    "\n",
    "for d in raw_docs:\n",
    "    text = d.page_content or \"\"\n",
    "    props = extract_propositions(text, llm, debug=False)\n",
    "\n",
    "    # Fallback if the model returns non-JSON or empty\n",
    "    if not props:\n",
    "        props = [text]\n",
    "\n",
    "    for p in props:\n",
    "        prop_docs.append(\n",
    "            Document(\n",
    "                page_content=p,\n",
    "                metadata={**(d.metadata or {}), \"source_type\": \"proposition\"},\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Built {len(prop_docs)} proposition documents.\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Vector index (FAISS local) using Databricks embeddings\n",
    "# -----------------------------\n",
    "vectorstore = FAISS.from_documents(prop_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Retrieval + answer using Databricks chat LLM\n",
    "# -----------------------------\n",
    "ANSWER_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"Answer the question using ONLY the context below.\n",
    "If the context is insufficient, say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join(f\"- {d.page_content}\" for d in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | ANSWER_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "query = \"When was the Eiffel Tower built?\"\n",
    "answer = qa_chain.invoke(query)\n",
    "\n",
    "print(\"\\n=== Answer ===\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d02df87-b3d3-4437-b2e4-8652ffa99d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Node_Parser",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}