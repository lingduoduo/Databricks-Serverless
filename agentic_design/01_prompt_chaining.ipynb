{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc94837a-86f2-4ff8-b1bf-c40fbcbcd8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -q databricks-langchain langchain==0.3.7 faiss-cpu wikipedia langgraph==0.5.3  databricks_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c4878a-34a0-466d-8a77-34d802a685b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76216f23-819f-492c-806f-405888b6d542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prompt Chaining - LangChain Expression Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d719ec2d-68b3-4f97-b358-05f533ff3ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Databricks chat model wrapper\n",
    "from databricks_langchain import ChatDatabricks  # pip install databricks-langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4b61ab4-4a08-4cdd-8040-4b2a444bd77b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-1-8b-instruct\" # Model Serving endpoint name; other option see \"Serving\" under AI/ML tab (e.g. databricks-gpt-oss-20b)\n",
    "\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2ad5bd-3f9a-4ff9-afdc-72801840e2a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Prompt 1: Extract Information ---\n",
    "prompt_extract = ChatPromptTemplate.from_template(\n",
    "    \"Extract the technical specifications from the following text:\\n\\n{text_input}\"\n",
    ")\n",
    "\n",
    "# --- Prompt 2: Transform to JSON ---\n",
    "prompt_transform = ChatPromptTemplate.from_template(\n",
    "    \"Transform the following specifications into a JSON object with 'cpu', 'memory', and 'storage' as keys:\\n\\n{specifications}\"\n",
    ")\n",
    "\n",
    "# --- Build the Chain using LCEL ---\n",
    "extraction_chain = prompt_extract | llm | StrOutputParser()\n",
    "\n",
    "full_chain = (\n",
    "    {\"specifications\": extraction_chain}\n",
    "    | prompt_transform\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- Run the Chain ---\n",
    "input_text = \"The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\"\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})\n",
    "\n",
    "print(\"\\n--- Final JSON Output ---\")\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a7861cc-6820-4ee7-9817-cc7ca0fa0ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### LangChain Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af58be52-63a1-4fb2-a6ac-1223ab2dd334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Simulated sub-agent handlers ----------\n",
    "def booking_handler(request: str) -> str:\n",
    "    print(\"\\n--- DELEGATING TO BOOKING HANDLER ---\")\n",
    "    return f\"Booking Handler processed request: '{request}'. Result: Simulated booking action.\"\n",
    "\n",
    "def info_handler(request: str) -> str:\n",
    "    print(\"\\n--- DELEGATING TO INFO HANDLER ---\")\n",
    "    return f\"Info Handler processed request: '{request}'. Result: Simulated information retrieval.\"\n",
    "\n",
    "def unclear_handler(request: str) -> str:\n",
    "    print(\"\\n--- HANDLING UNCLEAR REQUEST ---\")\n",
    "    return f\"Coordinator could not delegate request: '{request}'. Please clarify.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f647666-17a4-4b91-867f-4e40f89a2535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Router chain ----------\n",
    "coordinator_router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Analyze the user's request and determine which specialist handler should process it.\n",
    "- If the request is related to booking flights or hotels, output 'booker'.\n",
    "- For all other general information questions, output 'info'.\n",
    "- If the request is unclear or doesn't fit either category, output 'unclear'.\n",
    "ONLY output one word: 'booker', 'info', or 'unclear'.\"\"\"),\n",
    "    (\"user\", \"{request}\")\n",
    "])\n",
    "\n",
    "coordinator_router_chain = coordinator_router_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f788b894-752d-4146-a5be-cb605065fd74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableBranch\n",
    "\n",
    "# ---------- Delegation logic ----------\n",
    "delegation_branch = RunnableBranch(\n",
    "    (lambda x: x[\"decision\"].strip() == \"booker\",\n",
    "     RunnablePassthrough.assign(output=lambda x: booking_handler(x[\"input\"][\"request\"]))),\n",
    "\n",
    "    (lambda x: x[\"decision\"].strip() == \"info\",\n",
    "     RunnablePassthrough.assign(output=lambda x: info_handler(x[\"input\"][\"request\"]))),\n",
    "\n",
    "    # default\n",
    "    RunnablePassthrough.assign(output=lambda x: unclear_handler(x[\"input\"][\"request\"]))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3136d437-c921-48b8-b68c-bc3265e75495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coordinator_agent = (\n",
    "    {\"decision\": coordinator_router_chain, \"input\": RunnablePassthrough()}\n",
    "    | delegation_branch\n",
    "    | (lambda x: x[\"output\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "709ddecb-ade5-4ee2-aac2-aad92051fdc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Running with a booking request ---\")\n",
    "print(coordinator_agent.invoke({\"request\": \"Book me a flight to London.\"}))\n",
    "\n",
    "print(\"\\n--- Running with an info request ---\")\n",
    "print(coordinator_agent.invoke({\"request\": \"What is the capital of Italy?\"}))\n",
    "\n",
    "print(\"\\n--- Running with an unclear request ---\")\n",
    "print(coordinator_agent.invoke({\"request\": \"Tell me about quantum physics.\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f449c33-7b8b-4025-9505-a4aa856ddd88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parallelization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b786e94e-a277-4ca4-925b-ed64b1453c48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable, RunnableParallel, RunnablePassthrough\n",
    "import asyncio\n",
    "\n",
    "# --- Define Independent Chains (run in parallel) ---\n",
    "summarize_chain: Runnable = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Summarize the following topic concisely:\"),\n",
    "        (\"user\", \"{topic}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "questions_chain: Runnable = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Generate three interesting questions about the following topic:\"),\n",
    "        (\"user\", \"{topic}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "terms_chain: Runnable = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Identify 5-10 key terms from the following topic, separated by commas:\"),\n",
    "        (\"user\", \"{topic}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7db0b0d0-117b-4b0c-9010-bc33bcc77aa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Build the Parallel + Synthesis Chain ---\n",
    "map_chain = RunnableParallel(\n",
    "    {\n",
    "        \"summary\": summarize_chain,\n",
    "        \"questions\": questions_chain,\n",
    "        \"key_terms\": terms_chain,\n",
    "        \"topic\": RunnablePassthrough(),  # pass original input through\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa5a128f-fc31-40a0-8f0d-a2e5d9b69caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "synthesis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Based on the following information:\n",
    "Summary: {summary}\n",
    "Related Questions: {questions}\n",
    "Key Terms: {key_terms}\n",
    "Synthesize a comprehensive answer.\"\"\"),\n",
    "    (\"user\", \"Original topic: {topic}\")\n",
    "])\n",
    "\n",
    "full_parallel_chain = map_chain | synthesis_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ce18a8-011f-432d-a192-f9cd4575276d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Run the Chain ---\n",
    "async def run_parallel_example(topic: str) -> None:\n",
    "    if not llm:\n",
    "        print(\"LLM not initialized. Cannot run example.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Running Parallel LangChain Example for Topic: '{topic}' ---\")\n",
    "    try:\n",
    "        response = await full_parallel_chain.ainvoke(topic)  # pass a single string\n",
    "        print(\"\\n--- Final Response ---\")\n",
    "        print(response)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during chain execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00971cb4-fa9c-4e24-a752-8a4ebf06331e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Run the Chain ---\n",
    "async def run_parallel_example(topic: str) -> None:\n",
    "    if not llm:\n",
    "        print(\"LLM not initialized. Cannot run example.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Running Parallel LangChain Example for Topic: '{topic}' ---\")\n",
    "    try:\n",
    "        response = await full_parallel_chain.ainvoke(topic)  # pass a single string\n",
    "        print(\"\\n--- Final Response ---\")\n",
    "        print(response)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during chain execution: {e}\")\n",
    "\n",
    "# Directly await the coroutine in notebook cell (Databricks supports top-level await)\n",
    "test_topic = \"The history of space exploration\"\n",
    "await run_parallel_example(test_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "348d92e9-de76-49eb-bab2-28558d5a712a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_prompt_chaining",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
