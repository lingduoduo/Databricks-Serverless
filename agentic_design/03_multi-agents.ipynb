{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc94837a-86f2-4ff8-b1bf-c40fbcbcd8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -q databricks-langchain langchain==0.3.7 faiss-cpu wikipedia langgraph==0.5.3  databricks_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c4878a-34a0-466d-8a77-34d802a685b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76216f23-819f-492c-806f-405888b6d542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Multi-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d719ec2d-68b3-4f97-b358-05f533ff3ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import Optional, List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tools import tool as langchain_tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "\n",
    "from databricks_langchain import ChatDatabricks \n",
    "from langgraph.graph import StateGraph, END  # pip install langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4b61ab4-4a08-4cdd-8040-4b2a444bd77b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 1) Environment / LLM\n",
    "# -----------------------\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-1-8b-instruct\" # Model Serving endpoint name; other option see \"Serving\" under AI/ML tab (e.g. databricks-gpt-oss-20b)\n",
    "\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2ad5bd-3f9a-4ff9-afdc-72801840e2a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "\n",
    "# -----------------------\n",
    "# 2) State definition\n",
    "# -----------------------\n",
    "class BlogState(TypedDict, total=False):\n",
    "    topic: str\n",
    "    research: str\n",
    "    blog_post: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78ce7372-360a-4b60-a31d-adcfe28fc028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 3) Node: Researcher\n",
    "# -----------------------\n",
    "def researcher_node(state: BlogState) -> BlogState:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a Senior Research Analyst.\n",
    "Research the top 3 emerging trends in AI in 2024–2025.\n",
    "Focus on practical applications and potential impact.\n",
    "Include sources (links or clear citations) for each trend.\"\"\"),\n",
    "        (\"user\", \"Topic: {topic}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    research = chain.invoke({\"topic\": state[\"topic\"]})\n",
    "    return {\"research\": research}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2a097bf-5142-474c-889f-82f1d0842595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 4) Node: Writer\n",
    "# -----------------------\n",
    "def writer_node(state: BlogState) -> BlogState:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a Technical Content Writer.\n",
    "Write an engaging ~500-word blog post for a general audience.\n",
    "Use the research notes below. Keep it clear and practical.\n",
    "\n",
    "Research notes:\n",
    "{research}\n",
    "\"\"\"),\n",
    "        (\"user\", \"Write the blog post about: {topic}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    blog_post = chain.invoke({\"topic\": state[\"topic\"], \"research\": state[\"research\"]})\n",
    "    return {\"blog_post\": blog_post}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2394ef47-e1ae-4b3b-afca-b7692ced2d6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 5) Build the LangGraph\n",
    "# -----------------------\n",
    "def build_graph():\n",
    "    graph = StateGraph(BlogState)\n",
    "\n",
    "    graph.add_node(\"researcher\", researcher_node)\n",
    "    graph.add_node(\"writer\", writer_node)\n",
    "\n",
    "    graph.set_entry_point(\"researcher\")\n",
    "    graph.add_edge(\"researcher\", \"writer\")\n",
    "    graph.add_edge(\"writer\", END)\n",
    "\n",
    "    return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf8f13d-bae4-4022-b992-fee5d7a3b2a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app = build_graph()\n",
    "\n",
    "initial_state: BlogState = {\"topic\": \"Top 3 emerging trends in Artificial Intelligence in 2024–2025\"}\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n================ RESEARCH ================\\n\")\n",
    "print(final_state[\"research\"])\n",
    "print(\"\\n================ BLOG POST ================\\n\")\n",
    "print(final_state[\"blog_post\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a7861cc-6820-4ee7-9817-cc7ca0fa0ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Memory Manangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f647666-17a4-4b91-867f-4e40f89a2535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Dummy embedder for InMemoryStore (replace with a real embedding model in prod)\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    return [[1.0, 2.0] for _ in texts]\n",
    "\n",
    "store = InMemoryStore(index={\"embed\": embed, \"dims\": 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f788b894-752d-4146-a5be-cb605065fd74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "\n",
    "# -------------------------\n",
    "# 1) Graph state\n",
    "# -------------------------\n",
    "class AgentState(TypedDict, total=False):\n",
    "    user_id: str\n",
    "    app: str\n",
    "    messages: List[BaseMessage]          # short-term chat history\n",
    "    user_input: str                      # current user turn\n",
    "    instructions: str                    # current system instructions\n",
    "    response: str                        # model response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3136d437-c921-48b8-b68c-bc3265e75495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Helpers: store keys\n",
    "# -------------------------\n",
    "def ns(state: AgentState):\n",
    "    return (state[\"user_id\"], state[\"app\"])\n",
    "\n",
    "INSTR_KEY = \"agent_instructions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa17acce-07f0-45f9-95a5-602df109b6a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 3) Node A: load instructions (from store)\n",
    "# -------------------------\n",
    "def load_instructions(state: AgentState) -> AgentState:\n",
    "    namespace = ns(state)\n",
    "    got = store.get(namespace, INSTR_KEY)\n",
    "    if got:\n",
    "        instructions = got.value[\"instructions\"]\n",
    "    else:\n",
    "        instructions = \"You are a helpful assistant. Be concise.\"\n",
    "        store.put(namespace, INSTR_KEY, {\"instructions\": instructions})\n",
    "    return {\"instructions\": instructions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9e2e178-efa5-4767-84eb-fcd5d995ef23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4) Node B: update instructions (reflect on convo)\n",
    "# -------------------------\n",
    "def update_instructions(state: AgentState) -> AgentState:\n",
    "    # Reflect on the conversation and improve the system instructions\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You improve an assistant’s system instructions over time.\n",
    "Given the current instructions and recent conversation, produce an updated instruction set.\n",
    "Rules:\n",
    "- Keep it short (<= 8 bullet points).\n",
    "- Only add stable preferences or rules inferred from the conversation.\n",
    "- Don’t invent personal facts.\n",
    "Return only the updated instructions text.\"\"\"),\n",
    "        (\"human\", \"Current instructions:\\n{instructions}\\n\\nConversation:\\n{conversation}\")\n",
    "    ])\n",
    "\n",
    "    conversation_text = \"\\n\".join(\n",
    "        [f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\" for m in state.get(\"messages\", [])]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    new_instructions = chain.invoke({\n",
    "        \"instructions\": state[\"instructions\"],\n",
    "        \"conversation\": conversation_text\n",
    "    })\n",
    "\n",
    "    store.put(ns(state), INSTR_KEY, {\"instructions\": new_instructions})\n",
    "    return {\"instructions\": new_instructions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59781103-e63f-4935-bdfe-8ec5392d4cf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# -------------------------\n",
    "# 5) Node C: call model (use instructions + chat history)\n",
    "# -------------------------\n",
    "def call_model(state: AgentState) -> AgentState:\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"{instructions}\"),\n",
    "        MessagesPlaceholder(\"messages\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\n",
    "        \"instructions\": state[\"instructions\"],\n",
    "        \"messages\": state.get(\"messages\", []),\n",
    "        \"user_input\": state[\"user_input\"],\n",
    "    })\n",
    "\n",
    "    # append to short-term history\n",
    "    new_messages = list(state.get(\"messages\", [])) + [HumanMessage(content=state[\"user_input\"]), AIMessage(content=response)]\n",
    "    return {\"response\": response, \"messages\": new_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c59f4a32-aadb-449d-bbca-2ffc8bc6cfb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 6) Build graph: load -> call -> update -> end\n",
    "# -------------------------\n",
    "def build_graph():\n",
    "    g = StateGraph(AgentState)\n",
    "    g.add_node(\"load_instructions\", load_instructions)\n",
    "    g.add_node(\"call_model\", call_model)\n",
    "    g.add_node(\"update_instructions\", update_instructions)\n",
    "\n",
    "    g.set_entry_point(\"load_instructions\")\n",
    "    g.add_edge(\"load_instructions\", \"call_model\")\n",
    "    g.add_edge(\"call_model\", \"update_instructions\")\n",
    "    g.add_edge(\"update_instructions\", END)\n",
    "\n",
    "    return g.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75ee1627-e67f-44d4-81a0-29733a0ab345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app = build_graph()\n",
    "state: AgentState = {\n",
    "    \"user_id\": \"my-user\",\n",
    "    \"app\": \"chitchat\",\n",
    "    \"messages\": [],\n",
    "    \"user_input\": \"Hi, I'm Ling. Please keep answers short.\",\n",
    "}\n",
    "out = app.invoke(state)\n",
    "print(\"Assistant:\", out[\"response\"])\n",
    "\n",
    "state = {\n",
    "    \"user_id\": \"my-user\",\n",
    "    \"app\": \"chitchat\",\n",
    "    \"messages\": out[\"messages\"],\n",
    "    \"user_input\": \"Do you remember my preference?\",\n",
    "}\n",
    "out2 = app.invoke(state)\n",
    "print(\"Assistant:\", out2[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "348d92e9-de76-49eb-bab2-28558d5a712a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_multi-agents",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
