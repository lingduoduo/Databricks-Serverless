{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc94837a-86f2-4ff8-b1bf-c40fbcbcd8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 2.18.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0m\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q databricks-langchain langchain==0.3.7 faiss-cpu wikipedia langgraph==0.5.3  databricks_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c4878a-34a0-466d-8a77-34d802a685b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76216f23-819f-492c-806f-405888b6d542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Multi-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d719ec2d-68b3-4f97-b358-05f533ff3ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import Optional, List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tools import tool as langchain_tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "\n",
    "from databricks_langchain import ChatDatabricks \n",
    "from langgraph.graph import StateGraph, END  # pip install langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4b61ab4-4a08-4cdd-8040-4b2a444bd77b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 1) Environment / LLM\n",
    "# -----------------------\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-1-8b-instruct\" # Model Serving endpoint name; other option see \"Serving\" under AI/ML tab (e.g. databricks-gpt-oss-20b)\n",
    "\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2ad5bd-3f9a-4ff9-afdc-72801840e2a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "\n",
    "# -----------------------\n",
    "# 2) State definition\n",
    "# -----------------------\n",
    "class BlogState(TypedDict, total=False):\n",
    "    topic: str\n",
    "    research: str\n",
    "    blog_post: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78ce7372-360a-4b60-a31d-adcfe28fc028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 3) Node: Researcher\n",
    "# -----------------------\n",
    "def researcher_node(state: BlogState) -> BlogState:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a Senior Research Analyst.\n",
    "Research the top 3 emerging trends in AI in 2024–2025.\n",
    "Focus on practical applications and potential impact.\n",
    "Include sources (links or clear citations) for each trend.\"\"\"),\n",
    "        (\"user\", \"Topic: {topic}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    research = chain.invoke({\"topic\": state[\"topic\"]})\n",
    "    return {\"research\": research}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2a097bf-5142-474c-889f-82f1d0842595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 4) Node: Writer\n",
    "# -----------------------\n",
    "def writer_node(state: BlogState) -> BlogState:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a Technical Content Writer.\n",
    "Write an engaging ~500-word blog post for a general audience.\n",
    "Use the research notes below. Keep it clear and practical.\n",
    "\n",
    "Research notes:\n",
    "{research}\n",
    "\"\"\"),\n",
    "        (\"user\", \"Write the blog post about: {topic}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    blog_post = chain.invoke({\"topic\": state[\"topic\"], \"research\": state[\"research\"]})\n",
    "    return {\"blog_post\": blog_post}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2394ef47-e1ae-4b3b-afca-b7692ced2d6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 5) Build the LangGraph\n",
    "# -----------------------\n",
    "def build_graph():\n",
    "    graph = StateGraph(BlogState)\n",
    "\n",
    "    graph.add_node(\"researcher\", researcher_node)\n",
    "    graph.add_node(\"writer\", writer_node)\n",
    "\n",
    "    graph.set_entry_point(\"researcher\")\n",
    "    graph.add_edge(\"researcher\", \"writer\")\n",
    "    graph.add_edge(\"writer\", END)\n",
    "\n",
    "    return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf8f13d-bae4-4022-b992-fee5d7a3b2a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================ RESEARCH ================\n\nBased on industry reports, research studies, and expert opinions, here are the top 3 emerging trends in Artificial Intelligence (AI) for 2024-2025, along with their practical applications and potential impact:\n\n**Trend 1: Explainable AI (XAI) and Transparency**\n\nExplainable AI (XAI) is a growing trend that focuses on making AI models more transparent and interpretable. This trend aims to address the lack of trust in AI decision-making processes, particularly in high-stakes applications like healthcare, finance, and law enforcement.\n\nPractical Applications:\n\n* **Medical Diagnosis**: XAI can help doctors understand how AI-powered diagnostic tools arrive at their conclusions, enabling more accurate and transparent diagnosis.\n* **Financial Risk Assessment**: XAI can provide insights into how AI-driven risk assessment models make decisions, reducing the risk of biased or unfair lending practices.\n\nPotential Impact:\n\n* Increased trust in AI decision-making processes\n* Improved accountability and transparency in AI-driven applications\n* Enhanced collaboration between humans and AI systems\n\nSources:\n\n* \"Explainable AI: A Survey\" by the Association for the Advancement of Artificial Intelligence (AAAI) [1]\n* \"Explainable AI for Healthcare\" by the National Institutes of Health (NIH) [2]\n\n**Trend 2: Edge AI and IoT**\n\nEdge AI refers to the processing of AI workloads at the edge of the network, closer to the source of the data. This trend is driven by the increasing number of Internet of Things (IoT) devices and the need for real-time processing and decision-making.\n\nPractical Applications:\n\n* **Smart Cities**: Edge AI can enable real-time traffic management, energy optimization, and public safety monitoring in smart cities.\n* **Industrial Automation**: Edge AI can improve manufacturing efficiency, quality control, and predictive maintenance in industrial settings.\n\nPotential Impact:\n\n* Reduced latency and improved real-time decision-making\n* Increased efficiency and productivity in various industries\n* Enhanced security and reduced data transmission costs\n\nSources:\n\n* \"Edge AI: A New Paradigm for AI\" by the IEEE Computer Society [3]\n* \"Edge AI for IoT\" by the International Journal of Advanced Research in Computer Science (IJARCS) [4]\n\n**Trend 3: Human-AI Collaboration and Hybrid Intelligence**\n\nHuman-AI collaboration involves designing AI systems that work alongside humans to augment their capabilities and improve decision-making. This trend is driven by the recognition that AI is not a replacement for human intelligence, but rather a complement to it.\n\nPractical Applications:\n\n* **Creative Industries**: Human-AI collaboration can enable the creation of new art forms, music, and literature that combine human creativity with AI-generated ideas.\n* **Business Decision-Making**: Human-AI collaboration can provide business leaders with data-driven insights and recommendations that inform strategic decision-making.\n\nPotential Impact:\n\n* Improved productivity and efficiency in various industries\n* Enhanced creativity and innovation through human-AI collaboration\n* Increased trust and acceptance of AI in various applications\n\nSources:\n\n* \"Human-AI Collaboration: A New Frontier\" by the Harvard Business Review [5]\n* \"Hybrid Intelligence: A New Paradigm for AI\" by the MIT Technology Review [6]\n\nReferences:\n\n[1] AAAI. (2020). Explainable AI: A Survey. Association for the Advancement of Artificial Intelligence.\n\n[2] NIH. (2020). Explainable AI for Healthcare. National Institutes of Health.\n\n[3] IEEE Computer Society. (2020). Edge AI: A New Paradigm for AI. IEEE Computer Society.\n\n[4] IJARCS. (2020). Edge AI for IoT. International Journal of Advanced Research in Computer Science.\n\n[5] Harvard Business Review. (2020). Human-AI Collaboration: A New Frontier. Harvard Business Review.\n\n[6] MIT Technology Review. (2020). Hybrid Intelligence: A New Paradigm for AI. MIT Technology Review.\n\n================ BLOG POST ================\n\n**The Future of Artificial Intelligence: Top 3 Emerging Trends in 2024-2025**\n\nArtificial Intelligence (AI) has been transforming industries and revolutionizing the way we live and work. As we step into 2024-2025, the AI landscape is expected to undergo significant changes, driven by advancements in technology, shifting business needs, and evolving societal expectations. In this blog post, we'll explore the top 3 emerging trends in AI that will shape the future of technology and its applications.\n\n**Trend 1: Explainable AI (XAI) and Transparency**\n\nOne of the most significant concerns surrounding AI is the lack of transparency and accountability in its decision-making processes. This is where Explainable AI (XAI) comes in – a trend that focuses on making AI models more interpretable and transparent. XAI aims to address the trust deficit in AI-driven applications, particularly in high-stakes domains like healthcare, finance, and law enforcement.\n\nBy using XAI, medical professionals can understand how AI-powered diagnostic tools arrive at their conclusions, leading to more accurate and transparent diagnosis. Similarly, in finance, XAI can provide insights into how AI-driven risk assessment models make decisions, reducing the risk of biased or unfair lending practices.\n\nThe potential impact of XAI is substantial:\n\n* Increased trust in AI decision-making processes\n* Improved accountability and transparency in AI-driven applications\n* Enhanced collaboration between humans and AI systems\n\n**Trend 2: Edge AI and IoT**\n\nAs the number of Internet of Things (IoT) devices continues to grow, the need for real-time processing and decision-making becomes increasingly important. Edge AI, which involves processing AI workloads at the edge of the network, is poised to revolutionize various industries.\n\nEdge AI can enable real-time traffic management, energy optimization, and public safety monitoring in smart cities. In industrial settings, Edge AI can improve manufacturing efficiency, quality control, and predictive maintenance. By processing data closer to the source, Edge AI reduces latency, improves efficiency, and enhances security.\n\nThe potential impact of Edge AI is significant:\n\n* Reduced latency and improved real-time decision-making\n* Increased efficiency and productivity in various industries\n* Enhanced security and reduced data transmission costs\n\n**Trend 3: Human-AI Collaboration and Hybrid Intelligence**\n\nThe idea of AI replacing human intelligence is a myth. In reality, AI is a complement to human capabilities, and the future of AI lies in human-AI collaboration. This trend involves designing AI systems that work alongside humans to augment their capabilities and improve decision-making.\n\nHuman-AI collaboration can enable the creation of new art forms, music, and literature that combine human creativity with AI-generated ideas. In business, human-AI collaboration can provide leaders with data-driven insights and recommendations that inform strategic decision-making.\n\nThe potential impact of human-AI collaboration is substantial:\n\n* Improved productivity and efficiency in various industries\n* Enhanced creativity and innovation through human-AI collaboration\n* Increased trust and acceptance of AI in various applications\n\nIn conclusion, the top 3 emerging trends in AI for 2024-2025 – Explainable AI, Edge AI, and Human-AI Collaboration – will shape the future of technology and its applications. As these trends continue to evolve, we can expect significant advancements in various industries, from healthcare and finance to manufacturing and creative fields.\n\nBy embracing these trends, businesses and organizations can unlock new opportunities, improve decision-making, and drive innovation. As we look to the future, one thing is clear: AI is no longer a novelty, but a fundamental part of our technological landscape.\n\nStay ahead of the curve by staying informed about the latest developments in AI. Follow us for more insights and updates on the future of Artificial Intelligence.\n"
     ]
    }
   ],
   "source": [
    "app = build_graph()\n",
    "\n",
    "initial_state: BlogState = {\"topic\": \"Top 3 emerging trends in Artificial Intelligence in 2024–2025\"}\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n================ RESEARCH ================\\n\")\n",
    "print(final_state[\"research\"])\n",
    "print(\"\\n================ BLOG POST ================\\n\")\n",
    "print(final_state[\"blog_post\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a7861cc-6820-4ee7-9817-cc7ca0fa0ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Memory Manangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f647666-17a4-4b91-867f-4e40f89a2535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Dummy embedder for InMemoryStore (replace with a real embedding model in prod)\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    return [[1.0, 2.0] for _ in texts]\n",
    "\n",
    "store = InMemoryStore(index={\"embed\": embed, \"dims\": 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f788b894-752d-4146-a5be-cb605065fd74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "\n",
    "# -------------------------\n",
    "# 1) Graph state\n",
    "# -------------------------\n",
    "class AgentState(TypedDict, total=False):\n",
    "    user_id: str\n",
    "    app: str\n",
    "    messages: List[BaseMessage]          # short-term chat history\n",
    "    user_input: str                      # current user turn\n",
    "    instructions: str                    # current system instructions\n",
    "    response: str                        # model response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3136d437-c921-48b8-b68c-bc3265e75495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Helpers: store keys\n",
    "# -------------------------\n",
    "def ns(state: AgentState):\n",
    "    return (state[\"user_id\"], state[\"app\"])\n",
    "\n",
    "INSTR_KEY = \"agent_instructions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa17acce-07f0-45f9-95a5-602df109b6a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 3) Node A: load instructions (from store)\n",
    "# -------------------------\n",
    "def load_instructions(state: AgentState) -> AgentState:\n",
    "    namespace = ns(state)\n",
    "    got = store.get(namespace, INSTR_KEY)\n",
    "    if got:\n",
    "        instructions = got.value[\"instructions\"]\n",
    "    else:\n",
    "        instructions = \"You are a helpful assistant. Be concise.\"\n",
    "        store.put(namespace, INSTR_KEY, {\"instructions\": instructions})\n",
    "    return {\"instructions\": instructions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9e2e178-efa5-4767-84eb-fcd5d995ef23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4) Node B: update instructions (reflect on convo)\n",
    "# -------------------------\n",
    "def update_instructions(state: AgentState) -> AgentState:\n",
    "    # Reflect on the conversation and improve the system instructions\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You improve an assistant’s system instructions over time.\n",
    "Given the current instructions and recent conversation, produce an updated instruction set.\n",
    "Rules:\n",
    "- Keep it short (<= 8 bullet points).\n",
    "- Only add stable preferences or rules inferred from the conversation.\n",
    "- Don’t invent personal facts.\n",
    "Return only the updated instructions text.\"\"\"),\n",
    "        (\"human\", \"Current instructions:\\n{instructions}\\n\\nConversation:\\n{conversation}\")\n",
    "    ])\n",
    "\n",
    "    conversation_text = \"\\n\".join(\n",
    "        [f\"Human: {m.content}\" if isinstance(m, HumanMessage) else f\"AI: {m.content}\" for m in state.get(\"messages\", [])]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    new_instructions = chain.invoke({\n",
    "        \"instructions\": state[\"instructions\"],\n",
    "        \"conversation\": conversation_text\n",
    "    })\n",
    "\n",
    "    store.put(ns(state), INSTR_KEY, {\"instructions\": new_instructions})\n",
    "    return {\"instructions\": new_instructions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59781103-e63f-4935-bdfe-8ec5392d4cf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# -------------------------\n",
    "# 5) Node C: call model (use instructions + chat history)\n",
    "# -------------------------\n",
    "def call_model(state: AgentState) -> AgentState:\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"{instructions}\"),\n",
    "        MessagesPlaceholder(\"messages\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\n",
    "        \"instructions\": state[\"instructions\"],\n",
    "        \"messages\": state.get(\"messages\", []),\n",
    "        \"user_input\": state[\"user_input\"],\n",
    "    })\n",
    "\n",
    "    # append to short-term history\n",
    "    new_messages = list(state.get(\"messages\", [])) + [HumanMessage(content=state[\"user_input\"]), AIMessage(content=response)]\n",
    "    return {\"response\": response, \"messages\": new_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c59f4a32-aadb-449d-bbca-2ffc8bc6cfb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 6) Build graph: load -> call -> update -> end\n",
    "# -------------------------\n",
    "def build_graph():\n",
    "    g = StateGraph(AgentState)\n",
    "    g.add_node(\"load_instructions\", load_instructions)\n",
    "    g.add_node(\"call_model\", call_model)\n",
    "    g.add_node(\"update_instructions\", update_instructions)\n",
    "\n",
    "    g.set_entry_point(\"load_instructions\")\n",
    "    g.add_edge(\"load_instructions\", \"call_model\")\n",
    "    g.add_edge(\"call_model\", \"update_instructions\")\n",
    "    g.add_edge(\"update_instructions\", END)\n",
    "\n",
    "    return g.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75ee1627-e67f-44d4-81a0-29733a0ab345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hi Ling. What can I help you with?\nAssistant: You prefer short answers.\n"
     ]
    }
   ],
   "source": [
    "app = build_graph()\n",
    "state: AgentState = {\n",
    "    \"user_id\": \"my-user\",\n",
    "    \"app\": \"chitchat\",\n",
    "    \"messages\": [],\n",
    "    \"user_input\": \"Hi, I'm Ling. Please keep answers short.\",\n",
    "}\n",
    "out = app.invoke(state)\n",
    "print(\"Assistant:\", out[\"response\"])\n",
    "\n",
    "state = {\n",
    "    \"user_id\": \"my-user\",\n",
    "    \"app\": \"chitchat\",\n",
    "    \"messages\": out[\"messages\"],\n",
    "    \"user_input\": \"Do you remember my preference?\",\n",
    "}\n",
    "out2 = app.invoke(state)\n",
    "print(\"Assistant:\", out2[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "348d92e9-de76-49eb-bab2-28558d5a712a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_multi-agents",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}